ğŸ“„ LLM GURU App â€“ AI Question Answering from Documents

Weâ€™re excited to share the final results of our project, LLM GURU App â€“ AI Question Answering from Documents.

This system enables users to upload PDFs, process them into searchable chunks with OpenAI embeddings, and retrieve precise answers to their questions. Itâ€™s designed for fast, scalable deployment and open-source collaborationâ€”ideal for researchers, teams, and public knowledge sharing.

â¸»

ğŸŒ Public Access & Showcase

The full results of this work have been showcased and published under an open license. You can:
	â€¢	ğŸ”— View Source Code: https://github.com/your-username/pdf-rag-app
	â€¢	ğŸŒ Live Demo (if deployed): https://your-app-demo-link.com (optional)
	â€¢	ğŸ“¦ Dockerized Setup: Ready for local and cloud deployments.

We welcome feedback, contributions, and real-world use cases.

â¸»

ğŸš€ Features
	â€¢	ğŸ“¥ PDF Upload & Processing â€“ Upload PDFs and auto-process their content.
	â€¢	ğŸ” Semantic Search â€“ Query using OpenAI embeddings for precise context.
	â€¢	ğŸ“¦ Qdrant Vector Store â€“ Stores and retrieves embedded chunks efficiently.
	â€¢	ğŸ“ API Ready â€“ Endpoints for uploading and querying PDFs.

â¸»

ğŸ“‚ Project Structure

/src
  |-- routes/
        uploadPdf.ts      # API for PDF upload and embedding
        queryPdf.ts       # API for querying PDF content
  |-- utils/
        textSplitter.ts   # Handles text splitting logic
        embedder.ts       # OpenAI embedding setup
  |-- app.ts              # Express app entry point
docker-compose.db.yml     # Docker setup for Qdrant
README.md                 # Project documentation


â¸»

âš™ï¸ Installation

Prerequisites
	â€¢	Node.js >= 18
	â€¢	Docker & Docker Compose (for Qdrant)
	â€¢	OpenAI API Key

Steps

# Clone repository
git clone https://github.com/your-username/pdf-rag-app.git
cd pdf-rag-app

# Install dependencies
npm install

# Start Qdrant with Docker
docker-compose -f docker-compose.db.yml up -d

# Set environment variables
echo "OPENAI_API_KEY=sk-..." > .env

# Run the server
npm run dev


â¸»

ğŸ›  API Endpoints

POST /api/upload

Upload a PDF file for processing.
Headers: Content-Type: multipart/form-data
Body: file=<your-pdf-file>

POST /api/query

Query the ingested PDFs.
Body:

{
  "question": "How big is BMC Software in Houston, TX?"
}


â¸»

ğŸ§ª Running Tests

npm test


â¸»

ğŸ Roadmap
	â€¢	âœ… PDF upload & chunking
	â€¢	âœ… Semantic search with OpenAI embeddings
	â€¢	âœ… Filter responses by labelValue 1
	â€¢	â¬œ Add multi-user support and authentication
	â€¢	â¬œ Build frontend UI for uploads and queries
	â€¢	â¬œ Deploy to AWS Amplify / Vercel

â¸»

ğŸ“‹ Risk Log

Risk	Mitigation
OpenAI API rate limits	Batch embedding & retry logic
Large PDF file uploads	Enforce file size limits
Qdrant scaling for big data	Implement sharding & replication


â¸»

ğŸƒ Quickstart

Get up and running in under 10 minutes:

git clone https://github.com/your-username/pdf-rag-app.git
cd pdf-rag-app
npm install
docker-compose -f docker-compose.db.yml up -d
npm run dev


â¸»

ğŸ“œ License

This project is published under the MIT License, making it freely available for modification and distribution.

â¸»

ğŸ™ Credits

OpenAI â€“ https://openai.com/
LangChain â€“ https://www.langchain.com/
Qdrant â€“ https://qdrant.tech/
Express.js â€“ https://expressjs.com/
Docker â€“ https://www.docker.com/

Thanks to all team members for helping achieve this in just 30 hours! Your contributions made this possible.

â¸»

ğŸ’¡ Call for Contributions

This is an open-source project. Fork it, star it â­, and help us make it even better. Share your ideas, fixes, or feature requests via pull requests or issues.
